{
 "metadata": {
  "name": "",
  "signature": "sha256:cdc8cc9e7699e57731e9b607ee4bf9db8a306a02660827dcff81340c2863c485"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  Author: Angela Chapman\n",
      "#  Date: 8/6/2014\n",
      "#\n",
      "#  This file contains code to accompany the Kaggle tutorial\n",
      "#  \"Deep learning goes to the movies\".  The code in this file\n",
      "#  is for Part 1 of the tutorial on Natural Language Processing.\n",
      "#\n",
      "# *************************************** #\n",
      "\n",
      "import os\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    train = pd.read_csv(os.path.join(os.path.dirname(__file__), 'data', 'labeledTrainData.tsv'), header=0, \\\n",
      "                    delimiter=\"\\t\", quoting=3)\n",
      "    test = pd.read_csv(os.path.join(os.path.dirname(__file__), 'data', 'testData.tsv'), header=0, delimiter=\"\\t\", \\\n",
      "                   quoting=3 )\n",
      "\n",
      "    print 'The first review is:'\n",
      "    print train[\"review\"][0]\n",
      "\n",
      "    raw_input(\"Press Enter to continue...\")\n",
      "\n",
      "\n",
      "    print 'Download text data sets. If you already have NLTK datasets downloaded, just close the Python download window...'\n",
      "    #nltk.download()  # Download text data sets, including stop words\n",
      "\n",
      "    # Initialize an empty list to hold the clean reviews\n",
      "    clean_train_reviews = []\n",
      "\n",
      "    # Loop over each review; create an index i that goes from 0 to the length\n",
      "    # of the movie review list\n",
      "\n",
      "    print \"Cleaning and parsing the training set movie reviews...\\n\"\n",
      "    for i in xrange( 0, len(train[\"review\"])):\n",
      "        clean_train_reviews.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], True)))\n",
      "\n",
      "\n",
      "    # ****** Create a bag of words from the training set\n",
      "    #\n",
      "    print \"Creating the bag of words...\\n\"\n",
      "\n",
      "\n",
      "    # Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
      "    # bag of words tool.\n",
      "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
      "                             tokenizer = None,    \\\n",
      "                             preprocessor = None, \\\n",
      "                             stop_words = None,   \\\n",
      "                             max_features = 5000)\n",
      "\n",
      "    # fit_transform() does two functions: First, it fits the model\n",
      "    # and learns the vocabulary; second, it transforms our training data\n",
      "    # into feature vectors. The input to fit_transform should be a list of\n",
      "    # strings.\n",
      "    train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
      "\n",
      "    # Numpy arrays are easy to work with, so convert the result to an\n",
      "    # array\n",
      "    train_data_features = train_data_features.toarray()\n",
      "\n",
      "    # ******* Train a random forest using the bag of words\n",
      "    #\n",
      "    print \"Training the random forest (this may take a while)...\"\n",
      "\n",
      "\n",
      "    # Initialize a Random Forest classifier with 100 trees\n",
      "    forest = RandomForestClassifier(n_estimators = 100)\n",
      "\n",
      "    # Fit the forest to the training set, using the bag of words as\n",
      "    # features and the sentiment labels as the response variable\n",
      "    #\n",
      "    # This may take a few minutes to run\n",
      "    forest = forest.fit( train_data_features, train[\"sentiment\"] )\n",
      "\n",
      "\n",
      "\n",
      "    # Create an empty list and append the clean reviews one by one\n",
      "    clean_test_reviews = []\n",
      "\n",
      "    print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
      "    for i in xrange(0,len(test[\"review\"])):\n",
      "        clean_test_reviews.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], True)))\n",
      "\n",
      "    # Get a bag of words for the test set, and convert to a numpy array\n",
      "    test_data_features = vectorizer.transform(clean_test_reviews)\n",
      "    test_data_features = test_data_features.toarray()\n",
      "\n",
      "    # Use the random forest to make sentiment label predictions\n",
      "    print \"Predicting test labels...\\n\"\n",
      "    result = forest.predict(test_data_features)\n",
      "\n",
      "    # Copy the results to a pandas dataframe with an \"id\" column and\n",
      "    # a \"sentiment\" column\n",
      "    output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
      "\n",
      "    # Use pandas to write the comma-separated output file\n",
      "    output.to_csv(os.path.join(os.path.dirname(__file__), 'data', 'Bag_of_Words_model.csv'), index=False, quoting=3)\n",
      "    print \"Wrote results to Bag_of_Words_model.csv\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}